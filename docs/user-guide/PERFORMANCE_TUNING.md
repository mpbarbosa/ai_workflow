# Performance Tuning Guide - AI Workflow Automation

**Version**: 4.0.0  
**Last Updated**: 2026-02-08

> ðŸš€ **Goal**: Optimize workflow execution for maximum speed and efficiency

## Table of Contents

1. [Quick Wins](#quick-wins)
2. [Optimization Strategies](#optimization-strategies)
3. [Performance Benchmarks](#performance-benchmarks)
4. [Advanced Optimization](#advanced-optimization)
5. [Resource Management](#resource-management)
6. [Monitoring & Profiling](#monitoring--profiling)

## Quick Wins

### 1. Enable Smart Execution (40-85% faster)

Skip unnecessary steps based on change analysis:

```bash
./src/workflow/execute_tests_docs_workflow.sh --smart-execution
```

**Performance by Change Type**:
- **Documentation only**: 85% faster (23 min â†’ 3.5 min)
- **Code changes**: 40% faster (23 min â†’ 14 min)
- **Mixed changes**: 40-60% faster depending on scope

**How it works**:
- Analyzes `git diff` to identify modified files
- Skips steps that don't apply to changed files
- Example: Doc changes skip code review and test generation

### 2. Enable Parallel Execution (33% faster)

Run independent steps simultaneously:

```bash
./src/workflow/execute_tests_docs_workflow.sh --parallel
```

**Performance**: Reduces total time by ~33% (23 min â†’ 15.5 min)

**System Requirements**:
- Multi-core CPU (4+ cores recommended)
- Sufficient RAM (8GB+ recommended)
- Fast disk I/O

**Best for**:
- Full workflow runs
- Systems with available resources
- When all dependencies are met

### 3. Combine Optimizations (57-90% faster)

Maximum performance with combined flags:

```bash
./src/workflow/execute_tests_docs_workflow.sh \
  --smart-execution \
  --parallel \
  --auto
```

**Performance**:
- Documentation changes: 90% faster (23 min â†’ 2.3 min)
- Code changes: 57% faster (23 min â†’ 10 min)
- Full changes: 33% faster (23 min â†’ 15.5 min)

### 4. Use Workflow Templates (Fastest)

Pre-configured workflows for common scenarios:

```bash
# Documentation only (3-4 min)
./templates/workflows/docs-only.sh

# Test development (8-10 min)
./templates/workflows/test-only.sh

# Feature development (15-20 min with all optimizations)
./templates/workflows/feature.sh
```

### 5. Enable AI Response Caching (60-80% token reduction)

Automatic in v2.3.0+, but verify it's working:

```bash
# Check cache statistics
cat src/workflow/.ai_cache/index.json | jq '.stats'

# Output shows:
# {
#   "hits": 450,      # Cache hits
#   "misses": 150,    # Cache misses
#   "hit_rate": 0.75  # 75% hit rate
# }
```

**Performance Impact**:
- 60-80% reduction in AI API calls
- Faster response times (cache reads vs. API calls)
- Lower costs (fewer tokens consumed)

**Disable if needed** (not recommended):
```bash
./src/workflow/execute_tests_docs_workflow.sh --no-ai-cache
```

## Optimization Strategies

### Strategy 1: Smart Execution Modes

**Use Case**: Different change types need different workflows

**Implementation**:

```bash
# Automatic detection
./src/workflow/execute_tests_docs_workflow.sh --smart-execution

# Manual step selection (v4.0.0+)
# Documentation updates only
./src/workflow/execute_tests_docs_workflow.sh \
  --steps change_analysis,documentation_updates,git_finalization

# Code changes only
./src/workflow/execute_tests_docs_workflow.sh \
  --steps change_analysis,code_review,test_execution,git_finalization

# Mixed workflow
./src/workflow/execute_tests_docs_workflow.sh \
  --steps change_analysis,documentation_updates,code_review,test_execution,git_finalization
```

**Best Practices**:
- Use `--smart-execution` for automatic detection
- Use `--steps` for predictable, repeatable workflows
- Combine with `--parallel` for maximum speed

### Strategy 2: Multi-Stage Pipeline (v2.8.0+)

**Use Case**: Progressive validation with early exit

**Implementation**:

```bash
./src/workflow/execute_tests_docs_workflow.sh \
  --multi-stage \
  --smart-execution \
  --parallel
```

**How it works**:
- **Stage 1** (Core - 3-5 min): Quick validation
  - Change analysis
  - Documentation validation
  - Fast tests
- **Stage 2** (Extended - 8-12 min): Comprehensive checks
  - Full test suite
  - Code review
  - Coverage analysis
- **Stage 3** (Finalization - 15-20 min): Final polish
  - UX analysis
  - Performance testing
  - Release prep

**Result**: 80%+ of runs complete in first 2 stages

**Force all stages**:
```bash
./src/workflow/execute_tests_docs_workflow.sh \
  --multi-stage \
  --manual-trigger
```

### Strategy 3: ML Optimization (v2.7.0+)

**Use Case**: Intelligent workflow optimization based on historical data

**Requirements**: 10+ previous workflow runs

**Implementation**:

```bash
# Check ML status
./src/workflow/execute_tests_docs_workflow.sh --show-ml-status

# Enable ML optimization
./src/workflow/execute_tests_docs_workflow.sh \
  --ml-optimize \
  --smart-execution \
  --parallel
```

**Performance**: 15-30% additional improvement beyond other optimizations

**How it works**:
- Analyzes historical execution data
- Predicts step durations
- Optimizes resource allocation
- Recommends skip strategies

**Training the model**:
```bash
# Run workflow 10+ times normally
for i in {1..10}; do
  ./src/workflow/execute_tests_docs_workflow.sh --auto
done

# Then enable ML optimization
./src/workflow/execute_tests_docs_workflow.sh --ml-optimize
```

### Strategy 4: Incremental Processing (v3.2.0+)

**Use Case**: Documentation analysis on large projects

**Automatically enabled in Step 1** when:
- 3+ documentation files
- Smart execution enabled
- Files can be analyzed independently

**Performance**: 75-85% faster for Step 1
- Average: 14.5 min â†’ 3 min
- Unchanged docs: 96% time savings (skipped)
- Parallel analysis: 71% time savings (concurrent AI calls)

**Manual control**:
```bash
# Force full analysis (disable incremental)
export DISABLE_INCREMENTAL_DOCS=1
./src/workflow/execute_tests_docs_workflow.sh
```

### Strategy 5: Selective Step Execution

**Use Case**: Run only necessary steps for specific tasks

**Examples**:

```bash
# Documentation workflow (3-4 min)
./src/workflow/execute_tests_docs_workflow.sh \
  --steps change_analysis,documentation_updates,git_finalization

# Testing workflow (8-10 min)
./src/workflow/execute_tests_docs_workflow.sh \
  --steps change_analysis,test_generation,test_execution,test_coverage

# Code quality workflow (10-12 min)
./src/workflow/execute_tests_docs_workflow.sh \
  --steps change_analysis,code_review,refactoring_suggestions,code_quality_check

# Release workflow (15-20 min)
./src/workflow/execute_tests_docs_workflow.sh \
  --steps change_analysis,documentation_updates,test_execution,version_update,git_finalization
```

**Pro tip**: Create shell aliases for common workflows
```bash
# Add to ~/.bashrc or ~/.zshrc
alias wf-docs='cd /path/to/project && /path/to/ai_workflow/src/workflow/execute_tests_docs_workflow.sh --steps change_analysis,documentation_updates,git_finalization'
alias wf-tests='cd /path/to/project && /path/to/ai_workflow/src/workflow/execute_tests_docs_workflow.sh --steps change_analysis,test_execution,test_coverage'
alias wf-full='cd /path/to/project && /path/to/ai_workflow/src/workflow/execute_tests_docs_workflow.sh --smart-execution --parallel --auto'
```

## Performance Benchmarks

### Baseline Performance (No Optimizations)

**Full workflow**: 23 minutes
- Change analysis: 2 min
- Documentation: 6 min
- Code review: 4 min
- Testing: 5 min
- Quality checks: 3 min
- Finalization: 3 min

### Optimization Comparison

| Optimization | Documentation Changes | Code Changes | Full Changes |
|--------------|----------------------|--------------|--------------|
| **Baseline** | 23 min | 23 min | 23 min |
| Smart Execution | 3.5 min (85% â†“) | 14 min (40% â†“) | 23 min (0%) |
| Parallel Execution | 15.5 min (33% â†“) | 15.5 min (33% â†“) | 15.5 min (33% â†“) |
| **Combined** | **2.3 min (90% â†“)** | **10 min (57% â†“)** | **15.5 min (33% â†“)** |
| + ML Optimize | 1.5 min (93% â†“) | 6-7 min (70-75% â†“) | 10-11 min (52-57% â†“) |
| + Multi-Stage | 1-2 min (91-96% â†“) | 5-8 min (65-78% â†“) | 8-12 min (48-65% â†“) |

### Step-Level Performance (v3.2.0+)

**Step 1 (Documentation Analysis)**:
- Baseline: 14.5 minutes
- With incremental processing: 3 minutes (75-85% faster)
- Unchanged docs: skipped (96% savings)
- Parallel analysis: concurrent AI calls (71% savings)

**Other Steps**:
- Most steps: 1-5 minutes
- AI-heavy steps: 3-8 minutes
- Test execution: Variable (depends on test suite)

### Real-World Examples

**Example 1: Documentation Update**
```bash
# Changes: 2 markdown files in docs/
./src/workflow/execute_tests_docs_workflow.sh --smart-execution --parallel

# Result:
# - Steps run: 0, 0a, 2, 12
# - Time: 2.5 minutes
# - Steps skipped: 3, 5, 6, 7, 8, 9, 10, 11 (code/test steps)
```

**Example 2: Bug Fix (Code Only)**
```bash
# Changes: 1 JavaScript file in src/
./src/workflow/execute_tests_docs_workflow.sh --smart-execution --parallel

# Result:
# - Steps run: 0, 0a, 3, 5, 6, 7, 12
# - Time: 9 minutes
# - Steps skipped: 2 (docs), 8, 9, 10, 11 (quality steps)
```

**Example 3: Feature Development**
```bash
# Changes: Multiple files in src/, docs/, tests/
./src/workflow/execute_tests_docs_workflow.sh \
  --smart-execution \
  --parallel \
  --ml-optimize \
  --multi-stage

# Result:
# - Steps run: All stages (Stage 1 â†’ Stage 2 â†’ Stage 3)
# - Time: 10-12 minutes (vs. 23 min baseline)
# - Optimization: 48-57% faster
```

## Advanced Optimization

### 1. Resource Allocation

**CPU Optimization**:
```bash
# Set parallel job limit
export MAX_PARALLEL_JOBS=4  # Limit concurrent steps

# CPU-intensive steps
# Assign more cores to specific steps
export STEP_CPU_LIMIT=2  # CPUs per step
```

**Memory Optimization**:
```bash
# Limit memory per step
export STEP_MEMORY_LIMIT="2G"

# Clear caches if memory constrained
rm -rf src/workflow/.ai_cache/*
rm -rf .ml_data/*
```

**Disk I/O Optimization**:
```bash
# Use tmpfs for temporary data (Linux)
sudo mount -t tmpfs -o size=2G tmpfs /tmp/workflow
export TMPDIR=/tmp/workflow

# Or use SSD for workflow directory
# Ensure src/workflow/ is on fast storage
```

### 2. AI Model Selection

**Speed vs. Quality Trade-offs**:

```yaml
# .workflow-config.yaml
ai:
  # Fast models (lower quality, faster)
  model: "gpt-4-turbo"
  # OR: "claude-3-haiku"
  
  # Balanced models (good quality, medium speed)
  model: "gpt-4"
  # OR: "claude-3-sonnet"
  
  # High-quality models (best quality, slower)
  model: "gpt-4o"
  # OR: "claude-3-opus"
```

**Model-Specific Performance**:
- **gpt-4-turbo**: 2-3x faster than gpt-4, 90% quality
- **claude-3-haiku**: 3-4x faster than sonnet, 85% quality
- **gpt-4o / claude-3-opus**: Slowest but highest quality

### 3. Custom Caching Strategies

**Aggressive Caching** (longer TTL):
```bash
# Extend cache TTL to 7 days
export AI_CACHE_TTL=$((7 * 24 * 3600))

./src/workflow/execute_tests_docs_workflow.sh
```

**Cache Prewarming**:
```bash
# Run workflow once to populate cache
./src/workflow/execute_tests_docs_workflow.sh --no-resume

# Subsequent runs use cache
./src/workflow/execute_tests_docs_workflow.sh
```

**Cache Management**:
```bash
# View cache size
du -sh src/workflow/.ai_cache/

# Clean old cache entries
find src/workflow/.ai_cache/ -mtime +7 -delete

# Optimize cache (remove invalid entries)
# Run periodically:
./src/workflow/lib/ai_cache.sh optimize
```

### 4. Network Optimization

**For AI API Calls**:
```bash
# Use connection pooling
export HTTP_KEEP_ALIVE=1

# Reduce timeout for faster failures
export AI_TIMEOUT=30  # 30 seconds

# Increase retry attempts
export AI_MAX_RETRIES=3
```

**For Git Operations**:
```bash
# Use shallow clones
git config --global fetch.depth 1

# Optimize git performance
git config --global core.preloadindex true
git config --global core.fscache true
```

### 5. Workflow Profiling

**Enable Profiling**:
```bash
# Profile execution
export PROFILE_WORKFLOW=1
./src/workflow/execute_tests_docs_workflow.sh

# Output: Detailed timing for each step and function
# Location: src/workflow/metrics/profile_YYYYMMDD_HHMMSS.json
```

**Analyze Profile Data**:
```bash
# View step durations
cat src/workflow/metrics/current_run.json | jq '.steps[] | {name: .name, duration: .duration}'

# Find slowest steps
cat src/workflow/metrics/current_run.json | jq '.steps | sort_by(.duration) | reverse | .[0:5]'

# Calculate total time by category
cat src/workflow/metrics/current_run.json | jq '
  .steps | 
  group_by(.category) | 
  map({category: .[0].category, total: (map(.duration) | add)})
'
```

## Resource Management

### System Requirements

**Minimum**:
- CPU: 2 cores
- RAM: 4 GB
- Disk: 2 GB free
- Network: Stable connection for AI APIs

**Recommended**:
- CPU: 4+ cores (for parallel execution)
- RAM: 8 GB (for large projects)
- Disk: 5 GB free (for caching and logs)
- Network: Fast, stable connection

**Optimal**:
- CPU: 8+ cores
- RAM: 16 GB
- Disk: 10 GB on SSD
- Network: High-speed, low-latency

### Resource Limits

**Set Limits**:
```bash
# CPU limit (using cpulimit tool)
cpulimit -e execute_tests_docs_workflow.sh -l 50  # 50% of one core

# Memory limit (using cgroups)
systemd-run --scope -p MemoryLimit=4G \
  ./src/workflow/execute_tests_docs_workflow.sh

# Time limit
timeout 30m ./src/workflow/execute_tests_docs_workflow.sh
```

### Monitoring Resources

**Real-time Monitoring**:
```bash
# Monitor workflow process
watch -n 2 'ps aux | grep execute_tests_docs_workflow'

# Monitor system resources
htop  # Interactive process viewer

# Monitor disk I/O
iotop  # I/O monitoring

# Monitor network
nethogs  # Network bandwidth per process
```

**Post-Execution Analysis**:
```bash
# Check metrics
cat src/workflow/metrics/current_run.json | jq '.system_metrics'

# View resource usage
cat src/workflow/metrics/current_run.json | jq '{
  cpu: .system_metrics.cpu_usage,
  memory: .system_metrics.memory_usage,
  disk: .system_metrics.disk_usage
}'
```

## Monitoring & Profiling

### Performance Metrics

**Collect Metrics** (automatic):
```bash
./src/workflow/execute_tests_docs_workflow.sh

# Metrics saved to:
# - src/workflow/metrics/current_run.json (latest run)
# - src/workflow/metrics/history.jsonl (all runs)
```

**View Metrics**:
```bash
# Current run summary
cat src/workflow/metrics/current_run.json | jq '{
  total_duration: .total_duration,
  steps_run: (.steps | length),
  optimizations: .optimizations
}'

# Historical trends
tail -10 src/workflow/metrics/history.jsonl | jq -s '
  map({date: .timestamp, duration: .total_duration}) | 
  sort_by(.date)
'

# Average duration over last 10 runs
tail -10 src/workflow/metrics/history.jsonl | jq -s '
  map(.total_duration) | 
  add / length
'
```

### Optimization Recommendations

**Get Recommendations**:
```bash
# ML-based recommendations (requires 10+ runs)
./src/workflow/execute_tests_docs_workflow.sh --show-ml-status

# Output includes:
# - Recommended optimizations
# - Expected time savings
# - Resource allocation suggestions
```

**Act on Recommendations**:
```bash
# Example recommendations:
# 1. Enable parallel execution (33% faster)
# 2. Use smart execution for doc changes (85% faster)
# 3. Enable ML optimization (15-30% additional improvement)

# Apply all recommendations:
./src/workflow/execute_tests_docs_workflow.sh \
  --smart-execution \
  --parallel \
  --ml-optimize \
  --multi-stage \
  --auto
```

### Continuous Improvement

**Track Performance Over Time**:
```bash
# Create performance dashboard
cat > performance_dashboard.sh << 'EOF'
#!/bin/bash
echo "=== Performance Dashboard ==="
echo
echo "Last 10 runs:"
tail -10 src/workflow/metrics/history.jsonl | jq -r '
  [.timestamp, .total_duration, .steps_run, .optimizations_enabled] | 
  @tsv
' | column -t

echo
echo "Average duration: $(tail -10 src/workflow/metrics/history.jsonl | jq -s 'map(.total_duration) | add / length')"
echo "Fastest run: $(jq -s 'map(.total_duration) | min' src/workflow/metrics/history.jsonl)"
echo "Slowest run: $(jq -s 'map(.total_duration) | max' src/workflow/metrics/history.jsonl)"
echo
echo "Optimization usage:"
tail -100 src/workflow/metrics/history.jsonl | jq -s '
  group_by(.optimizations_enabled) | 
  map({opts: .[0].optimizations_enabled, count: length})
'
EOF

chmod +x performance_dashboard.sh
./performance_dashboard.sh
```

## Summary: Recommended Configuration

### For Maximum Speed

```bash
#!/bin/bash
# fastest_workflow.sh

./src/workflow/execute_tests_docs_workflow.sh \
  --smart-execution \
  --parallel \
  --ml-optimize \
  --multi-stage \
  --auto \
  --no-resume

# Expected performance:
# - Documentation changes: 1-2 min (93-96% faster)
# - Code changes: 5-8 min (65-78% faster)
# - Full changes: 8-12 min (48-65% faster)
```

### For Best Quality

```bash
#!/bin/bash
# quality_workflow.sh

# Disable optimizations, use best AI models
cat > .workflow-config.yaml << 'EOF'
ai:
  model: "gpt-4o"  # Highest quality
project:
  kind: "nodejs_api"
tech_stack:
  primary_language: "javascript"
EOF

./src/workflow/execute_tests_docs_workflow.sh \
  --no-resume

# Expected duration: 23-30 minutes
# Quality: Highest possible
```

### For Balanced Performance

```bash
#!/bin/bash
# balanced_workflow.sh

./src/workflow/execute_tests_docs_workflow.sh \
  --smart-execution \
  --parallel \
  --auto

# Expected performance:
# - Documentation: 2-3 min (87-91% faster)
# - Code: 10-12 min (48-57% faster)
# - Full: 15-17 min (26-35% faster)
# Quality: High (90-95% of best quality)
```

---

**Last Updated**: 2026-02-08  
**Version**: 4.0.0  
**Maintainer**: Marcelo Pereira Barbosa (@mpbarbosa)
